{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from promptsource.templates import DatasetTemplates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for used in the preprint, \"Maybe Only 0.5% Data is Needed: A Preliminary Exploration of Low Training Data Instruction Tuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly pick a instruction template, followin the settings in Section 4.1 of the paper -- 0.5% dataset\n",
    "p3_datasets = {\n",
    "    'nli': ['rte', 'cb', 'anli_r1', 'anli_r2', 'anli_r3'], # Natural Language Inference\n",
    "    'sc': ['copa', 'hellaswag', 'storycloze'], # Sentence Complement\n",
    "    'wsd': ['winogrande', 'wsc'], # Word Sense Disambiguation\n",
    "    'cr': ['wic'], # Coreference Resolution\n",
    "}\n",
    "\n",
    "prompt_mapping = { # Mapping from dataset name to prompt template in bigscience/P3 \n",
    "    'rte': 'super_glue_rte_does_it_follow_that', # RTE\n",
    "    'cb': 'super_glue_cb_does_it_follow_that', # CB\n",
    "    'anli_r1': 'anli_does_it_follow_that_r1', # ANLI R1\n",
    "    'anli_r2': 'anli_does_it_follow_that_r2', # ANLI R2\n",
    "    'anli_r3': 'anli_does_it_follow_that_r3', # ANLI R3\n",
    "    'copa': 'super_glue_copa_cause_effect', # COPA\n",
    "    'hellaswag': 'hellaswag_complete_first_then', # HelloSwag\n",
    "    'storycloze': 'storycloze_choose_story_ending', # Story Cloze\n",
    "    'winogrande': 'winogrande_winogrande_xl_fill_in_the_blank', # Winogrande\n",
    "    'wsc': 'super_glue_wsc.fixed_replaced_with', # WSC\n",
    "    'wic': 'super_glue_wic_question_context', # WIC\n",
    "}\n",
    "\n",
    "dataset_path = {\n",
    "    'storycloze': './data/storycloze/'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "all_train_datasets = []\n",
    "all_test_datasets = []\n",
    "\n",
    "def process_p3_datasets(dataset):\n",
    "    # only keep the answer_choices, inputs_pretokenized and targets_pretokenized columns\n",
    "    dataset = dataset.remove_columns([col for col in dataset.column_names if col not in ['answer_choices', 'inputs_pretokenized', 'targets_pretokenized']])\n",
    "    # rename the columns to be consistent with the template\n",
    "    dataset = dataset.rename_column('answer_choices', 'choices')\n",
    "    dataset = dataset.rename_column('inputs_pretokenized', 'input')\n",
    "    dataset = dataset.rename_column('targets_pretokenized', 'label')\n",
    "\n",
    "    # add dataset name to the dataset\n",
    "    dataset = dataset.map(lambda example: {'dataset': dataset_name, 'category': category, 'prompt_template': prompt_template, **example})\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def process_storycloze_datasets(dataset, prompt_name, prompt_template):\n",
    "    dataset_name = 'storycloze'\n",
    "    category = 'sc'\n",
    "    dataset = dataset.map(lambda example: {'dataset': dataset_name, 'category': category, 'prompt_template': prompt_name, 'input': prompt_template.apply(example)[0], 'label': prompt_template.apply(example)[1], 'choices': [example['sentence_quiz1'], example['sentence_quiz2']]})\n",
    "    dataset = dataset.remove_columns([col for col in dataset.column_names if col not in ['dataset', 'category', 'prompt_template', 'input', 'label', 'choices']])\n",
    "\n",
    "    return dataset\n",
    "    \n",
    "for category, datasets in p3_datasets.items():\n",
    "    for dataset_name in datasets:\n",
    "        prompt_template = prompt_mapping[dataset_name]\n",
    "        if dataset_name == 'storycloze':\n",
    "            path = dataset_path[dataset_name]\n",
    "\n",
    "            prompt_name = ' '.join(prompt_template.split('_')[1:]).title()\n",
    "            prompt_template = DatasetTemplates('story_cloze/2016')[prompt_name]\n",
    "            def sample_random_wrong_answer(example):\n",
    "                sentence_quiz1 = example['sentence5']\n",
    "                sentence_quiz2 = random.choice(sentence5_collections)\n",
    "                answer_right_ending = 1\n",
    "                while sentence_quiz2 == sentence_quiz1:\n",
    "                    sentence_quiz2 = random.choice(sentence5_collections)\n",
    "                \n",
    "                # shuffle the order of the two sentences and keep the idx of the correct answer \"sentence_quiz1\"\n",
    "                if random.random() < 0.5:\n",
    "                    sentence_quiz1, sentence_quiz2 = sentence_quiz2, sentence_quiz1\n",
    "                    answer_right_ending = 2\n",
    "                return {'sentence_quiz1': sentence_quiz1, 'sentence_quiz2': sentence_quiz2, 'answer_right_ending': answer_right_ending}\n",
    "            \n",
    "            # add idx to the dataset\n",
    "            train_dataset = load_dataset(\"csv\", data_files=os.path.join(path, 'train.csv'))\n",
    "            test_dataset = load_dataset(\"csv\", data_files=os.path.join(path, 'validation.csv'))\n",
    "            sentence5_collections = train_dataset['train']['sentence5']\n",
    "\n",
    "            train_dataset = train_dataset['train'].map(lambda example: {**sample_random_wrong_answer(example), 'input_sentence_1': example['sentence1'], 'input_sentence_2': example['sentence2'], 'input_sentence_3': example['sentence3'], 'input_sentence_4': example['sentence4']})\n",
    "            test_dataset = test_dataset['train'].map(lambda example: {'input_sentence_1': example['InputSentence1'], 'input_sentence_2': example['InputSentence2'], 'input_sentence_3': example['InputSentence3'], 'input_sentence_4': example['InputSentence4'], 'sentence_quiz1': example['RandomFifthSentenceQuiz1'], 'sentence_quiz2': example['RandomFifthSentenceQuiz2'], 'answer_right_ending': example['AnswerRightEnding']})\n",
    "\n",
    "            train_dataset = process_storycloze_datasets(train_dataset, prompt_name, prompt_template)\n",
    "            test_dataset = process_storycloze_datasets(test_dataset, prompt_name, prompt_template)\n",
    "            \n",
    "        else:\n",
    "            train_dataset = load_dataset(\"bigscience/P3\", prompt_template, split='train')\n",
    "            test_dataset = load_dataset(\"bigscience/P3\", prompt_template, split='test')\n",
    "            \n",
    "            # Labels information does not exist in some test splits, use validation split instead\n",
    "            answer_choices = test_dataset['answer_choices'][0]\n",
    "            if test_dataset['targets_pretokenized'][0] not in answer_choices:\n",
    "                test_dataset = load_dataset(\"bigscience/P3\", prompt_template, split='validation')\n",
    "\n",
    "            # filter the dataset to only contain train_split and test_split\n",
    "            train_dataset = process_p3_datasets(train_dataset)\n",
    "            test_dataset = process_p3_datasets(test_dataset)\n",
    "            \n",
    "        all_train_datasets.append(train_dataset)\n",
    "        all_test_datasets.append(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all datasets\n",
    "from datasets import concatenate_datasets\n",
    "\n",
    "train_dataset = concatenate_datasets(all_train_datasets)\n",
    "test_dataset = concatenate_datasets(all_test_datasets)\n",
    "\n",
    "# combine train_dataset and test_dataset as 'train' and 'test' split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['choices', 'input', 'label', 'dataset', 'category', 'prompt_template'],\n",
       "        num_rows: 304955\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['choices', 'input', 'label', 'dataset', 'category', 'prompt_template'],\n",
       "        num_rows: 17255\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "dataset = DatasetDict({'train': train_dataset, 'test': test_dataset})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 305/305 [00:00<00:00, 419.69ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:05<00:00,  5.48s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 18/18 [00:00<00:00, 202.17ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n"
     ]
    }
   ],
   "source": [
    "# push to huggingface datasets hub\n",
    "dataset.push_to_hub('simonycl/p3_0.5_dataset', private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 741/741 [00:00<00:00, 4.30MB/s]\n",
      "Downloading data: 100%|██████████| 76.2M/76.2M [00:07<00:00, 9.67MB/s]\n",
      "Downloading data: 100%|██████████| 10.7M/10.7M [00:00<00:00, 12.3MB/s]\n",
      "Downloading data files: 100%|██████████| 2/2 [00:08<00:00,  4.38s/it]\n",
      "Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 1142.40it/s]\n",
      "Generating train split: 100%|██████████| 304955/304955 [00:00<00:00, 688231.80 examples/s]\n",
      "Generating test split: 100%|██████████| 17255/17255 [00:00<00:00, 439264.11 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['choices', 'input', 'label', 'dataset', 'category', 'prompt_template'],\n",
       "    num_rows: 304955\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3_subset_dataset = load_dataset('simonycl/p3_0.5_dataset', split='train')\n",
    "p3_subset_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
